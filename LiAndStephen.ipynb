{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import keras \n",
    "import msprime as msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "Ne = 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for converting to ms format.\n",
    "def to_mksample(file, hap, pos):\n",
    "    with open(file, 'w') as out:\n",
    "        out.write('ms test\\n')\n",
    "        out.write('1 2 3\\n')\n",
    "        out.write('\\n')\n",
    "        out.write('segsites: {0}\\n'.format(hap.shape[0]))\n",
    "        out.write('positions: ')\n",
    "        for p in pos:\n",
    "            out.write(str(np.round(p/pos[-1], 4)))\n",
    "            out.write(' ')\n",
    "        out.write('\\n')\n",
    "        for n in range(hap.shape[1]):\n",
    "            h = hap[:, n].tolist()\n",
    "            hstr = [str(val) for val in h]\n",
    "            st = ''.join(hstr)\n",
    "            out.write(st)\n",
    "            out.write('\\n')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_mksample('test.txt', hap, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate haplotypes and positions using msprime based on some inital settings.\n",
    "def generate_sample(r):\n",
    "    recombination_rate=r\n",
    "    mutation_rate = 2e-8\n",
    "    length = 1e4\n",
    "    Ne = 10000\n",
    "    sample_size = 20\n",
    "    tree_seqs = msp.simulate(sample_size=sample_size, Ne=Ne, length=length, recombination_rate=recombination_rate, mutation_rate=mutation_rate)\n",
    "    pos = []\n",
    "    for v in tree_seqs.variants():\n",
    "        pos.append(v.position)\n",
    "    haplotypes = tree_seqs.genotype_matrix()\n",
    "    return haplotypes, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the funtion to compute likelihood for a haplotype with specified order.\n",
    "def loglikelihood_2(haplotypes, pos, r):\n",
    "    def _theta(sample_size):\n",
    "        s = 0\n",
    "        for t in range(1, sample_size):\n",
    "            s += 1/t\n",
    "        return 1/s\n",
    "    num_snps, sample_size = haplotypes.shape\n",
    "#     print('num_snps', num_snps, 'sample_size', sample_size)\n",
    "    log_conditional_haps = [-num_snps*np.log(2)]\n",
    "    theta = _theta(sample_size)\n",
    "#     theta = 8e-4\n",
    "    lens = np.array(pos[1:]) - np.array(pos[:-1])\n",
    "    \n",
    "    for i in range(1, sample_size):\n",
    "        h = haplotypes[:, i]\n",
    "        a = []\n",
    "        alpha= []\n",
    "        # compute for a(0)\n",
    "        for j in range(i):\n",
    "            h_j = haplotypes[:, j]\n",
    "            if h_j[0] == h[0]:\n",
    "                gamma = i/(i+theta) + 1/2*theta/(i+theta)\n",
    "            else:\n",
    "                gamma = 1/2*theta/(i+theta)\n",
    "            a.append(gamma*1/i)\n",
    "        alpha.append(a.copy())\n",
    "        # compute for a(1),a(2),...,a(num_snps)\n",
    "        for s in range(1, num_snps):\n",
    "            a = []\n",
    "            for j in range(i):\n",
    "                h_j = haplotypes[:, j]\n",
    "                if h_j[s] == h[s]:\n",
    "                    gamma = i/(i+theta) + 1/2*theta/(i+theta)\n",
    "                else:\n",
    "                    gamma = 1/2*theta/(i+theta)\n",
    "                p = np.exp(-4*Ne*r*lens[s-1]/i)\n",
    "                res = gamma * (p*alpha[-1][j] + (1-p)/i*sum(alpha[-1]))\n",
    "                a.append(res)\n",
    "            alpha.append(a.copy())\n",
    "        log_conditional_haps.append(np.log(sum(alpha[-1])))\n",
    "    return sum(log_conditional_haps)\n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# golden bisection search for point estimation.\n",
    "def golden_bisection_search(haplotypes, pos, start, end, maxiters=500):\n",
    "    i = 0\n",
    "    p = 0.618\n",
    "    while (end-start > 1e-10) and (i < maxiters):\n",
    "        left = start + (end-start) * (1-p)\n",
    "        right = start + (end-start) * p\n",
    "        if shuffle_sum(haplotypes, pos, left) >= shuffle_sum(haplotypes, pos, right):\n",
    "            end = right\n",
    "        else:\n",
    "            start = left\n",
    "        print('%d start: %s, end: %s'%(i, start, end))\n",
    "        i += 1\n",
    "    return (start+end)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly choose 20 different orders for computing likelihood. It's important!\n",
    "def shuffle_sum(haplotypes, pos, r):\n",
    "    logs = [loglikelihood_2(haplotypes, pos, r)]\n",
    "    for i in range(20):\n",
    "        shuffled_hap = haplotypes.copy().T\n",
    "        np.random.shuffle(shuffled_hap)\n",
    "        shuffled_hap = shuffled_hap.T\n",
    "        logs.append(loglikelihood_2(shuffled_hap, pos, r))\n",
    "    return np.mean(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example for using generate_sample.\n",
    "hap, pos = generate_sample(r=3.2e-8)\n",
    "# for r in [1e-2, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6, 1e-6, 5e-7, 1e-7, 6e-8, 1e-8, 5e-9, 1e-9]:\n",
    "#         print(r, shuffle_sum(hap, pos, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 start: 1e-10, end: 6.180381999999999e-07\n",
      "1 start: 1e-10, end: 3.8198580759999995e-07\n",
      "2 start: 1e-10, end: 2.3610542909679996e-07\n",
      "3 start: 1e-10, end: 1.4595135518182237e-07\n",
      "4 start: 1e-10, end: 9.023613750236621e-08\n",
      "5 start: 1e-10, end: 5.5804132976462325e-08\n",
      "6 start: 2.137897879700861e-08, end: 5.5804132976462325e-08\n",
      "7 start: 2.137897879700861e-08, end: 4.2653724079911005e-08\n",
      "8 start: 2.137897879700861e-08, end: 3.4526771381842286e-08\n",
      "9 start: 2.6401435564415073e-08, end: 3.4526771381842286e-08\n",
      "10 start: 2.6401435564415073e-08, end: 3.142289309958509e-08\n",
      "11 start: 2.6401435564415073e-08, end: 2.9504696321150144e-08\n",
      "12 start: 2.6401435564415073e-08, end: 2.8319250712077346e-08\n",
      "13 start: 2.713404095082206e-08, end: 2.8319250712077346e-08\n",
      "14 start: 2.713404095082206e-08, end: 2.7866500583277826e-08\n",
      "15 start: 2.713404095082206e-08, end: 2.7586701003679724e-08\n",
      "16 start: 2.713404095082206e-08, end: 2.7413784863488098e-08\n",
      "17 start: 2.713404095082206e-08, end: 2.7306922688849673e-08\n",
      "18 start: 2.713404095082206e-08, end: 2.7240881864923124e-08\n",
      "19 start: 2.713404095082206e-08, end: 2.720006863573652e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.716705479327929e-08"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_bisection_search(hap, pos, 1e-10, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on some random data. there are totally 100 data and it does need some time to run that. I won't provide any result below.\n",
    "# and some plots and measurements are based on this prediction, which couldn't be given at this time. You could run it if you are interested in that.\n",
    "np.random.seed(1996)\n",
    "rs = np.random.rand(100) * 1e-6\n",
    "def test_accuracy(rs):\n",
    "    ests = []\n",
    "    for r in rs:\n",
    "        hap, pos = generate_sample(r)\n",
    "        est = golden_bisection_search(hap, pos, 1e-10, 1e-6)\n",
    "        ests.append(est)\n",
    "        print(i, np.log(est/r))\n",
    "    return ests\n",
    "ests = test_accuracy(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# boxplot analysis for log errors.\n",
    "ests = np.array(ests)\n",
    "logratios = np.log10(ests/rs)\n",
    "import matplotlib.pyplot as plt \n",
    "plt.title(r'$\\log \\frac{\\rho_{pred}}{\\rho_{true}}$')\n",
    "plt.boxplot(logratios)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test MAE with groundtruth.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(rs, ests)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot log errors as a distribution.\n",
    "import seaborn as sns\n",
    "plt.title(r'kdeplot of $log_{10}\\frac{r_{est}}{r_{true}}$')\n",
    "sns.distplot(logratios, bins=20)\n",
    "plt.xlabel('log(error)')\n",
    "plt.ylabel('density')\n",
    "plt.savefig('logerror', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for pytorch (always get Nan during computing gradients, I plan to work with that later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood_cuda(haplotypes, pos, r):\n",
    "    def _theta(sample_size):\n",
    "        s = 0\n",
    "        for t in range(1, sample_size):\n",
    "            s += 1/t\n",
    "        return 1/s\n",
    "    num_snps, sample_size = haplotypes.shape\n",
    "    print('num_snps', num_snps, 'sample_size', sample_size)\n",
    "    log_conditional_haps = [-num_snps*np.log(2)]\n",
    "    theta = _theta(sample_size)\n",
    "#     theta = 8e-4\n",
    "    lens = np.array(pos[1:]) - np.array(pos[:-1])\n",
    "    \n",
    "    for i in range(1, sample_size):\n",
    "        h = haplotypes[:, i]\n",
    "        px = [1/sample_size]\n",
    "        a = []\n",
    "        alpha= []\n",
    "        # compute for a(0)\n",
    "        for j in range(i):\n",
    "            h_j = haplotypes[:, j]\n",
    "            if h_j[0] == h[0]:\n",
    "                gamma = i/(i+theta) + 1/2*theta/(i+theta)\n",
    "            else:\n",
    "                gamma = 1/2*theta/(i+theta)\n",
    "            a.append(gamma*1/i)\n",
    "        alpha.append(a.copy())\n",
    "        # compute for a(1),a(2),...,a(num_snps)\n",
    "        for s in range(1, num_snps):\n",
    "            a = []\n",
    "            for j in range(i):\n",
    "                h_j = haplotypes[:, j]\n",
    "                if h_j[s] == h[s]:\n",
    "                    gamma = i/(i+theta) + 1/2*theta/(i+theta)\n",
    "                else:\n",
    "                    gamma = 1/2*theta/(i+theta)\n",
    "                p = torch.exp(-r*lens[s-1]/i)\n",
    "#                 print(gamma)\n",
    "                res = gamma * (p*alpha[-1][j] + (1-p)/i*sum(alpha[-1]))\n",
    "                a.append(res)\n",
    "            alpha.append(a.copy())\n",
    "        log_conditional_haps.append(torch.log(sum(alpha[-1])))\n",
    "    return -sum(log_conditional_haps)\n",
    "        \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "learning_rate=1e-8\n",
    "device = torch.device('cuda:0')\n",
    "r = torch.tensor(1e-6, device=device, dtype=torch.float, requires_grad=True)\n",
    "for i in range(200):\n",
    "    print(i)\n",
    "    pred = loglikelihood_cuda(haplotypes, pos, r)\n",
    "    pred.backward()\n",
    "    with torch.no_grad():\n",
    "        r -= learning_rate* r.grad\n",
    "        r.grad = None\n",
    "    print(r.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.tensor(1e-4, dtype=torch.float64, requires_grad=True)\n",
    "y = torch.exp(-r*100/10)\n",
    "y.backward()\n",
    "print(r.grad)\n",
    "print(np.exp(-10*r.item())*(-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((), device=device, dtype=torch.float, requires_grad=True)\n",
    "b = [a,2*a,a]\n",
    "c = b.copy()\n",
    "y = torch.exp(sum(b))\n",
    "y.backward()\n",
    "print(y, a.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.2",
   "language": "python",
   "name": "tf2.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
